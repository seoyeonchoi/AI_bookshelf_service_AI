{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"private_outputs":true,"provenance":[],"machine_shape":"hm","gpuType":"T4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","source":["!pip install nest-asyncio pyngrok\n","!pip install ultralytics\n","!ngrok config add-authtoken 2RYNDUBmbE25sk2CKIlbxWkeM7h_7MzgwnULZ1xZZcqj1T8pb #ngrok token key\n","!pip install opencv-contrib-python\n","!pip install --upgrade google-cloud-vision\n","!pip install flask_cors\n","#!pip install ultralytics\n","# !pip install -qe ultralytics\n","# %cd /content/drive/MyDrive/big project\n","# !git clone https://github.com/ultralytics/ultralytics"],"metadata":{"id":"dgCXgQkNHajz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from google.colab import drive\n","# %cd '/content/drive/MyDrive/big project/yolov8'\n","import ultralytics\n","import time\n","import os\n","import io\n","import cv2\n","import sys\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import platform\n","import types\n","from ultralytics import YOLO\n","from PIL import Image, ImageFont, ImageDraw\n","from google.cloud import vision\n","from flask import Flask, request, jsonify\n","import nest_asyncio\n","import base64\n","import shutil\n","from pyngrok import ngrok\n","from flask_cors import CORS\n","from multiprocessing import Pool\n","import time\n","\n","drive.mount('/content/drive')\n","sys.path.append(\"..\")\n","ultralytics.checks()\n","\n","# google cloud vision API access\n","os.environ['GOOGLE_APPLICATION_CREDENTIALS'] = '/content/drive/MyDrive/big project/yolov8/alpine-practice-390604-5960e4078cde.json'\n","client_options = {'api_endpoint': 'eu-vision.googleapis.com'}\n","client = vision.ImageAnnotatorClient(client_options=client_options)"],"metadata":{"id":"KX1g5OX_qWB8"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"a3J-BX9x8TDp"},"outputs":[],"source":["app = Flask(__name__)\n","cors = CORS(app, resources={r\"*\": {\"origins\": \"*\"}}, supports_credentials=True)\n","MAX_IMAGE_SIZE = 10 * 1024 * 1024  # 최대 이미지 크기 설정 (10MB)\n","model = YOLO('/content/drive/MyDrive/big project/yolov8/runs/segment/augment2/weights/aug_160.pt')\n","second_model = YOLO('/content/drive/MyDrive/big project/yolov8/runs/title/train/mistake_crop_300/weights/coin_best.pt')\n","def clear_directories():\n","    if os.path.exists('/content/request'):\n","        shutil.rmtree('/content/request')\n","    if os.path.exists('/content/runs'):\n","        shutil.rmtree('/content/runs')\n","    if os.path.exists('/content/cropped_images'):\n","        shutil.rmtree('/content/cropped_images')\n","\n","def parse_labels(label_path):\n","    with open(label_path, 'r') as f:\n","        lines = f.readlines()\n","\n","    labels = []\n","    for line in lines:\n","        # class와 좌표들을 분리합니다\n","        label_parts = line.split()\n","        class_label = label_parts[0]\n","        coordinates = list(map(float, label_parts[1:]))\n","        labels.append((class_label, coordinates))\n","\n","    return labels\n","\n","def crop_polygon(img, coordinates):\n","    # label을 클래스와 좌표로 분리합니다\n","    coordinates = list(map(float, coordinates))\n","\n","    # 좌표를 실제 픽셀 좌표로 변환합니다\n","    h, w = img.shape[:2]\n","    coordinates = np.array([(int(x * w), int(y * h)) for x, y in zip(coordinates[::2], coordinates[1::2])])\n","\n","    # 폴리곤에 해당하는 마스크를 만듭니다\n","    mask = np.zeros_like(img)\n","    cv2.fillPoly(mask, [coordinates], (255,)*img.shape[2])\n","\n","    # 마스크를 이용하여 이미지를 잘라냅니다\n","    cropped_img = np.where(mask==255, img, 0)\n","\n","    # Bounding rectangle를 찾습니다\n","    x, y, w, h = cv2.boundingRect(coordinates.reshape(-1, 1, 2).astype(np.int32))\n","    cropped_img = cropped_img[y:y+h, x:x+w]\n","\n","    return cropped_img\n","\n","def save_image_file(image_file, save_dir):\n","    filename = image_file.filename\n","    file_path = os.path.join(save_dir, filename)\n","\n","    # 이미지 크기 체크\n","    image_data = image_file.read()\n","    image_size = len(image_data)\n","    # print('이미지 사이즈:', image_size)\n","    # print('제한 사이즈:', MAX_IMAGE_SIZE)\n","    if image_size > MAX_IMAGE_SIZE:\n","        raise Exception(f\"Image file {filename} is too large.\")\n","\n","    with open(file_path, \"wb\") as f:\n","        f.write(image_data)\n","    if not os.path.exists(file_path):\n","        raise Exception(f\"Failed to save the image file {filename}.\")\n","\n","    return file_path\n","\n","@app.route('/')\n","def hello_world():\n","    return \"Hello Flask and Ngrok!\"\n","\n","@app.route(\"/img2title/\", methods=[\"POST\"])\n","def predict():\n","    if not request.method == \"POST\":\n","        return\n","\n","    if request.files.getlist(\"image\"):\n","        start_time = time.time()\n","        save_dir = \"/content/request\"\n","        os.makedirs(save_dir, exist_ok=True)\n","        os.makedirs('/content/cropped_images', exist_ok=True)\n","        file_paths = []\n","        for image_file in request.files.getlist(\"image\"):\n","            print(image_file)\n","            file_path = save_image_file(image_file, save_dir)\n","            file_paths.append(file_path)\n","    results = model.predict(source=save_dir,\n","                            conf=0.7,\n","                            iou=0.4,\n","                            save=True,\n","                            save_txt=True,\n","                            name='model_result',\n","                            device='cpu',\n","                            retina_masks=True,\n","                            show_labels=False,\n","                            show_conf=False,\n","                            boxes=False,\n","                            )\n","\n","    responses = {\"data\": {}, \"segment_images\": {}, \"success\": 1}\n","    id_counter = 1\n","    for file_path in file_paths:\n","        filename = os.path.basename(file_path)\n","        filename_without_ext = os.path.splitext(filename)[0]\n","        # detected image show\n","        # Possible extensions\n","        extensions = [\".jpg\", \".jpeg\", \".png\", \".bmp\"]\n","\n","        # Check for all possible extensions\n","        segment_image = None\n","        for ext in extensions:\n","            potential_path = f'/content/runs/segment/model_result/{filename_without_ext}{ext}'\n","            if os.path.exists(potential_path):\n","                segment_image = potential_path\n","                # img2txt by base64 encoding\n","                with open(segment_image, \"rb\") as f:\n","                    segment_image_base64 = base64.b64encode(f.read()).decode()\n","                responses[\"segment_images\"][filename_without_ext] = segment_image_base64\n","                break\n","\n","        # If no image was found\n","        if segment_image is None:\n","            print(f\"No segmented image found for {filename_without_ext}. Skipping this image.\")\n","            continue\n","\n","        img = cv2.imread(file_path)\n","        label_path = f'/content/runs/segment/model_result/labels/{filename_without_ext}.txt'\n","        labels = parse_labels(label_path)\n","        cropped_images = []\n","\n","        for i, label in enumerate(labels):\n","            class_label, coordinates = label\n","            cropped_img = crop_polygon(img, coordinates)\n","            cropped_img_rgb = cv2.cvtColor(cropped_img, cv2.COLOR_BGR2RGB)\n","            cropped_images.append(cropped_img_rgb)\n","            cv2.imwrite(f'/content/cropped_images/{filename_without_ext}_{i}.jpg', cv2.cvtColor(cropped_img_rgb, cv2.COLOR_RGB2BGR))\n","        # second yolo model\n","    second_results = second_model.predict(source='/content/cropped_images/',\n","                                        conf=0.7,\n","                                        iou=0.4,\n","                                        save=True,\n","                                        save_txt=True,\n","                                        name='second_model_result',\n","                                        device='cpu',\n","                                        retina_masks=True,\n","                                        show_labels=False,\n","                                        show_conf=False,\n","                                        boxes=False,\n","                                        )\n","\n","    image_dir = \"/content/runs/segment/second_model_result\"\n","    label_dir = \"/content/runs/segment/second_model_result/labels\"\n","\n","    # 잘린 이미지를 저장할 리스트 초기화\n","    cropped_titles = []\n","\n","    for filename in os.listdir(image_dir):\n","        if filename.endswith(\".jpg\"):\n","            img_path = os.path.join(image_dir, filename)\n","            label_path = os.path.join(label_dir, filename.replace(\".jpg\", \".txt\"))\n","\n","            # 이미지 로드\n","            img = cv2.imread(img_path)\n","\n","            # 라벨 파일이 존재하는 경우\n","            if os.path.exists(label_path):\n","                with open(label_path, \"r\") as file:\n","                    for line in file:\n","                        # 라벨 파싱\n","                        class_name, *coordinates = line.strip().split()\n","                        coordinates = list(map(float, coordinates))\n","\n","                        # 이미지 자르기\n","                        cropped_img = crop_polygon(img, coordinates)\n","\n","                        # Grayscale 변환\n","                        cropped_img_gray = cv2.cvtColor(cropped_img, cv2.COLOR_BGR2GRAY)\n","\n","                        # 잘린 이미지를 리스트에 추가\n","                        cropped_titles.append(cropped_img_gray)\n","            # 라벨 파일이 존재하지 않는 경우\n","            else:\n","                img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n","                cropped_titles.append(img)\n","\n","    extracted_titles = []\n","    for i, data in enumerate(cropped_titles):\n","        image = cv2.cvtColor(data, cv2.COLOR_RGB2BGR)\n","        image = vision.Image(content=cv2.imencode('.jpg', image)[1].tobytes())\n","        response = client.text_detection(image=image)\n","        texts = response.text_annotations\n","        if not texts:  # texts가 비어있는 경우\n","            print(f\"No text detected in cropped image {i}. Skipping this image.\")\n","            continue\n","        # text box별 정보 추출\n","        txt_blocks,title = [],''\n","        for text in texts[1:]:\n","            if text :\n","                ocr_text = text.description\n","                txt_blocks.append(ocr_text) # 검출한 text box의 폭,너비,글자 넣기\n","            else :\n","                title='no_title_in_this_segmentation'\n","                continue\n","        # title 추출(책등에서 제목이 가장 큰 글씨라고 가정)\n","        for txt in txt_blocks:\n","            title += txt\n","        print(txt_blocks)\n","        extracted_titles.append(title)\n","\n","    for title in extracted_titles:\n","        responses[\"data\"][id_counter] = title\n","        id_counter += 1\n","\n","    clear_directories()\n","    end_time = time.time()\n","    elapsed_time = end_time - start_time\n","    print(\"Elapsed time: {} seconds\".format(elapsed_time))\n","    print(f\"Received images: {len(file_paths)}\")\n","    print(f\"Detected books: {len(extracted_titles)}\")\n","    print('data: ', responses['data'])\n","    # print(texts)\n","    # print(txt_blocks)\n","    return jsonify(responses)\n","\n","ngrok_tunnel = ngrok.connect(8000)\n","print('Public URL:', ngrok_tunnel.public_url)\n","nest_asyncio.apply()\n","app.run(host=\"0.0.0.0\", port=8000)"]},{"cell_type":"code","source":["# clear_directories()"],"metadata":{"id":"LfeVtz1gH9so"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"qHsa3FBhnwfV"},"execution_count":null,"outputs":[]}]}